{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6f817a-1506-43a8-af10-1314b5510744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twython\n",
      "  Downloading https://files.pythonhosted.org/packages/db/08/9921df4cb5829858dbd580ebd8a5a4b9e75a0b8295bc1e98963a983a0621/twython-3.9.1-py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from twython) (2.32.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 11.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.1.0->twython) (2.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.1.0->twython) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.1.0->twython) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.1.0->twython) (2024.7.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, twython\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-2.0.0 twython-3.9.1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e5b7bb-d241-4f73-836c-c63467942017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->vaderSentiment) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->vaderSentiment) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->vaderSentiment) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->vaderSentiment) (2.2.2)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899de3ca-9193-47e7-972b-f3e5f4812804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/20/f56d5b88450593ccde3f283e338f3f976b2e479bddd9a147f14f66ee1ca7/matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3MB)\n",
      "\u001b[K     |████████████████████████████████| 8.3MB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/b1/c8f428bae932a27ce9c87e7b21aba8ea3e820aa11413c5a795868c37e039/pillow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3MB 99.9MB/s eta 0:00:01     |█████████████▋                  | 1.8MB 99.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/b1/40655f6c3fa11ce740e8a964fa8e4c0479c87d6a7944b95af799c7a55dfe/kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 40.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/11/57335544a3027e9b96a05948c32e566328e3a2f84b7b99a325b7a06d2b06/contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 82.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (24.1)\n",
      "Collecting pyparsing>=2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/ec/2eb3cd785efd67806c46c13a17339708ddc346cbb684eade7a6e6f79536a/pyparsing-3.2.0-py3-none-any.whl (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 99.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting fonttools>=4.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/3e/0841e7bf38ad317c960992dd03bac041899a1c21396013e6ddcfd2bc48c5/fonttools-4.55.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6MB 96.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib) (3.19.2)\n",
      "Installing collected packages: pillow, kiwisolver, contourpy, pyparsing, cycler, fonttools, importlib-resources, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.55.0 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e43df1a-7736-442d-b78b-2897931c6ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.9/site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.9/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.9/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib!=3.6.1,>=3.4->seaborn) (3.19.2)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "692a1bca-5b8c-47c4-9a8c-8b837df913d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (0.13.2)\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl\n",
      "Collecting plotly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/ae/580600f441f6fc05218bd6c9d5794f4aef072a7d9093b291f1c50a9db8bc/plotly-5.24.1-py3-none-any.whl (19.1MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1MB 11.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 97.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (4.66.4)\n",
      "Collecting wordcloud\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/29/5fd253433d880dd91a0e058e292fae5828277166e988204638ede2a3e6ce/wordcloud-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (513kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 110.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (4.55.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl\n",
      "Collecting regex>=2021.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/44/2101cc0890c3621b90365c9ee8d7291a597c0722ad66eccd6ffa7f1bcc09/regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780kB)\n",
      "\u001b[K     |████████████████████████████████| 788kB 71.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 101.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl (97kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 34.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib) (3.19.2)\n",
      "Installing collected packages: colorama, tenacity, plotly, regex, joblib, click, nltk, wordcloud\n",
      "Successfully installed click-8.1.7 colorama-0.4.6 joblib-1.4.2 nltk-3.9.1 plotly-5.24.1 regex-2024.11.6 tenacity-9.0.0 wordcloud-1.9.4\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib seaborn colorama plotly nltk tqdm wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e941b5-c4b9-4189-b30b-5c190ef657f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2044/1673985938.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package vader_lexicon to /home/mosaic-\n",
      "[nltk_data]     ai/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/mosaic-ai/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/mosaic-\n",
      "[nltk_data]     ai/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore, init\n",
    "import plotly.express as px\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7435ba-a622-472f-8f63-fc44f3afb048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fosforml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/2e/3613fd0ccdbf3709dec86f87fe7624737a6f08bd1a813c88e65e7352dfde/fosforml-1.1.8-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 3.7MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting scikit-learn==1.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/89/dce01a35d354159dcc901e3c7e7eb3fe98de5cb3639c6cd39518d8830caa/scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9MB 8.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-ml-python==1.5.0; python_version <= \"3.9\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/c0fa5a9bc811a59a5a1c7113ff89676ed1629d7d6463db8c1a8c97a8b5f6/snowflake_ml_python-1.5.0-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 66.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==2.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.4.2)\n",
      "Collecting scipy>=1.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6MB)\n",
      "\u001b[K     |████████████████████████████████| 38.6MB 86.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.26.4)\n",
      "Requirement already satisfied: importlib-resources<7,>=6.1.1 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (6.4.5)\n",
      "Collecting sqlparse<1,>=0.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/13/5f6654c9d915077fae255686ca6fa42095b62b7337e3e1aa9e82caa6f43a/sqlparse-0.5.2-py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 20.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting anyio<4,>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl (80kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 25.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging<24,>=20.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 21.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-connector-python[pandas]<4,>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/83/f8b30648768b33fa28786932164db320d9fce662dfe1cbd4c6031736b9b2/snowflake_connector_python-3.12.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 98.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py<2,>=0.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/87/de5c32fa1b1c6c3305d576e299801d8655c175ca9557019906247b994331/absl_py-1.4.0-py3-none-any.whl (126kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 90.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying<2,>=1.3.3\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/04/9e36f28be4c0532c0e9207ff9dc01fb13a2b0eb036476a213b0000837d0e/retrying-1.3.4-py3-none-any.whl\n",
      "Collecting s3fs<2024,>=2022.11\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/d6/b8a748b7d3fc7b0fd2ede1cf26a80281d65cc24d5d56b66c3a4c87e256e2/s3fs-2023.12.2-py3-none-any.whl\n",
      "Collecting catboost<1.3,>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/4a/8ada4fb635601943805cbeeb288f70982fefe48a7cef63352e318435aa98/catboost-1.2.7-cp39-cp39-manylinux2014_x86_64.whl (98.7MB)\n",
      "\u001b[K     |████████████████████████████████| 98.7MB 308kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pytimeparse<2,>=1.1.8\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/b4/afd75551a3b910abd1d922dbd45e49e5deeb4d47dc50209ce489ba9844dd/pytimeparse-1.1.8-py2.py3-none-any.whl\n",
      "Collecting snowflake-snowpark-python!=1.12.0,<2,>=1.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/55/3cbf9670a6cc14690aa9c3cc279a5e6d8dc74ef2deb8ce6f8fb7d8268a35/snowflake_snowpark_python-1.25.0-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 85.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas<3,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (4.12.2)\n",
      "Collecting cachetools<6,>=3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml<7,>=6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (6.0.1)\n",
      "Collecting xgboost<2,>=1.7.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/3a/c9c5d4d5c49b132ef15ac7b5ccf56ef1c82efe36cd19414771762e97c00e/xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3MB)\n",
      "\u001b[K     |████████████████████████████████| 200.3MB 105kB/s s eta 0:00:018MB 132.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]<2024,>=2022.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/25/fab23259a52ece5670dcb8452e1af34b89e6135ecc17cd4b54b4b479eac6/fsspec-2023.12.2-py3-none-any.whl (168kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 106.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/19/1e47418efd3fadf343cc3c01703aba76e327e4f2224a1d137b7e2e5647ec/pyarrow-18.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.1MB)\n",
      "\u001b[K     |████████████████████████████████| 40.1MB 59.3MB/s eta 0:00:01████████      | 32.6MB 59.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from importlib-resources<7,>=6.1.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.19.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.2.2)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (42.0.5)\n",
      "Collecting sortedcontainers>=2.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.3.2)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (24.0.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.16.0)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/7f/09065fd9e27da0eda08b4d6897f1c13535066174cc023af248fc2a8d5e5a/asn1crypto-1.5.1-py2.py3-none-any.whl (105kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 86.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.1)\n",
      "Collecting filelock<4,>=3.5\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/f8/feced7779d755758a52d1f6635d990b8d98dc0a29fa568bbe0625f18fdf3/filelock-3.16.1-py3-none-any.whl\n",
      "Collecting pyjwt<3.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/1d/ef9b066e7ef60494c94173dc9f0b9adf5d9ec5f888109f5c669f53d4144b/PyJWT-2.10.0-py3-none-any.whl\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (4.2.2)\n",
      "Collecting urllib3<2.0.0,>=1.21.1; python_version < \"3.10\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/cf/8435d5a7159e2a9c83a95896ed596f68cf798005fe107cc655b5c5c14704/urllib3-1.26.20-py2.py3-none-any.whl (144kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 92.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.7.4)\n",
      "Collecting tomlkit\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.32.3)\n",
      "Requirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from retrying<2,>=1.3.3->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.16.0)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/57/6402242dde160d9ef9903487b4277443dc3da04615f6c4d3b48564a8ab57/aiobotocore-2.15.2-py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 17.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/61/a0515f4b71f91c0a3c54815d0e29f67932c1bc43ce75e703570eab21e011/aiohttp-3.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 97.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (from catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (5.24.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.9.2)\n",
      "Collecting graphviz\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/be/d59db2d1d52697c6adc9eacaf50e8965b6345cc143f671e1ed068818d5cf/graphviz-0.20.3-py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 15.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf<6,>=3.20\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/ae/3257b09328c0b4e59535e497b0c7537d4954038bdd53a2f0d2f49d15a7c4/protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 97.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzlocal\n",
      "  Downloading https://files.pythonhosted.org/packages/97/3f/c4c51c55ff8487f2e6d0e618dba917e3c3ee2caae6cf0fbb59c9b1876f2e/tzlocal-5.2-py3-none-any.whl\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python!=1.12.0,<2,>=1.11.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python!=1.12.0,<2,>=1.11.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (65.6.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas<3,>=1.0.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas<3,>=1.0.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.21)\n",
      "Collecting botocore<1.35.37,>=1.35.16\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/60/056d58b606731f94fe395266c604ea9efcecc10e6857ceb9b10e6831d746/botocore-1.35.36-py3-none-any.whl (12.6MB)\n",
      "\u001b[K     |████████████████████████████████| 12.6MB 74.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aioitertools<1.0.0,>=0.5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/85/13/58b70a580de00893223d61de8fea167877a3aed97d4a5e1405c9159ef925/aioitertools-0.12.0-py3-none-any.whl\n",
      "Collecting wrapt<2.0.0,>=1.10.10\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/e7/459a8a4f40f2fa65eb73cb3f339e6d152957932516d18d0e996c7ae2d7ae/wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 1.2MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting propcache>=0.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4e/97059dd24494d1c93d1efb98bb24825e1930265b41858dd59c15cb37a975/propcache-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 81.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (23.2.0)\n",
      "Collecting async-timeout<6.0,>=4.0; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d0/9973b1f127f7a419143877baf89d39767c83b828f492b4cac9fa085f85fd/yarl-1.17.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 111.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl\n",
      "Collecting frozenlist>=1.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/33/9f152105227630246135188901373c4f322cc026565ca6215b063f4c82f4/frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 84.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/41/0d0fb18c1ad574f807196f5f3d99164edf9de3e169a58c6dc2d6ed5742b9/multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 96.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d8/120cd0fe3e8530df0539e71ba9683eade12cae103dd7543e50d15f737917/aiohappyeyeballs-2.4.3-py3-none-any.whl\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly->catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (9.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (11.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.2.0)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/31/b4/b9b800c45527aadd64d5b442f9b932b00648617eb5d63d2c7a6587b7cafc/jmespath-1.0.1-py3-none-any.whl\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn, sqlparse, anyio, cloudpickle, packaging, sortedcontainers, asn1crypto, filelock, pyjwt, urllib3, tomlkit, pyarrow, snowflake-connector-python, absl-py, retrying, jmespath, botocore, aioitertools, wrapt, propcache, async-timeout, multidict, yarl, frozenlist, aiosignal, aiohappyeyeballs, aiohttp, aiobotocore, fsspec, s3fs, graphviz, catboost, pytimeparse, protobuf, tzlocal, snowflake-snowpark-python, cachetools, xgboost, snowflake-ml-python, fosforml\n",
      "  Found existing installation: anyio 4.4.0\n",
      "    Uninstalling anyio-4.4.0:\n",
      "      Successfully uninstalled anyio-4.4.0\n",
      "  Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "Successfully installed absl-py-1.4.0 aiobotocore-2.15.2 aiohappyeyeballs-2.4.3 aiohttp-3.11.2 aioitertools-0.12.0 aiosignal-1.3.1 anyio-3.7.1 asn1crypto-1.5.1 async-timeout-5.0.1 botocore-1.35.36 cachetools-5.5.0 catboost-1.2.7 cloudpickle-2.2.1 filelock-3.16.1 fosforml-1.1.8 frozenlist-1.5.0 fsspec-2023.12.2 graphviz-0.20.3 jmespath-1.0.1 multidict-6.1.0 packaging-23.2 propcache-0.2.0 protobuf-5.28.3 pyarrow-18.0.0 pyjwt-2.10.0 pytimeparse-1.1.8 retrying-1.3.4 s3fs-2023.12.2 scikit-learn-1.3.2 scipy-1.13.1 snowflake-connector-python-3.12.3 snowflake-ml-python-1.5.0 snowflake-snowpark-python-1.25.0 sortedcontainers-2.4.0 sqlparse-0.5.2 threadpoolctl-3.5.0 tomlkit-0.13.2 tzlocal-5.2 urllib3-1.26.20 wrapt-1.16.0 xgboost-1.7.6 yarl-1.17.2\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fosforml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eb9cedf-d0f2-41f2-8f93-e711faee26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281a1fbd-75c6-4278-91c2-9b84ce13498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPG_SCHEMA'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_session.connection.database\n",
    "my_session.connection.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "740b9e43-aa70-45a2-a98e-37ec64b95e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'SOCIAL_MEDIA_SENTIMENT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18144aa-2487-4e36-8f0b-afba2b9a65c0",
   "metadata": {},
   "source": [
    "sf_df = my_session.sql(\"select * from {} \".format(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff2213d8-181b-48de-ac11-31ec4019c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = my_session.sql(\"select * from {} \".format(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0f0b51-20d9-48fe-8fb6-8535ff0a9faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "snowflake.snowpark.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9847cf9-68f8-4c5f-bbdd-b2f7cd73b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62494299-fa0d-4594-b4fe-273cdf64ee03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f0aa4e-960a-4a14-bdae-b1ceead5c070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>USER</th>\n",
       "      <th>PLATFORM</th>\n",
       "      <th>HASHTAGS</th>\n",
       "      <th>RETWEETS</th>\n",
       "      <th>LIKES</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/15/2023 12:30</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1/15/2023 8:45</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! 💪</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/15/2023 15:45</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1/15/2023 18:20</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1/15/2023 19:55</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          TEXT SENTIMENT        TIMESTAMP  \\\n",
       "0        Enjoying a beautiful day at the park!  Positive  1/15/2023 12:30   \n",
       "1           Traffic was terrible this morning.  Negative   1/15/2023 8:45   \n",
       "2          Just finished an amazing workout! 💪  Positive  1/15/2023 15:45   \n",
       "3  Excited about the upcoming weekend getaway!  Positive  1/15/2023 18:20   \n",
       "4  Trying out a new recipe for dinner tonight.   Neutral  1/15/2023 19:55   \n",
       "\n",
       "         USER   PLATFORM            HASHTAGS  RETWEETS  LIKES    COUNTRY  \\\n",
       "0     User123    Twitter       #Nature #Park        15     30        USA   \n",
       "1   CommuterX    Twitter   #Traffic #Morning         5     10     Canada   \n",
       "2  FitnessFan  Instagram   #Fitness #Workout        20     40        USA   \n",
       "3  AdventureX   Facebook  #Travel #Adventure         8     15         UK   \n",
       "4    ChefCook  Instagram      #Cooking #Food        12     25  Australia   \n",
       "\n",
       "   YEAR  MONTH  DAY  HOUR  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d606f161-3440-4525-890a-c0dced158396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8bd2c_row0_col2, #T_8bd2c_row0_col3, #T_8bd2c_row1_col2, #T_8bd2c_row1_col3, #T_8bd2c_row2_col2, #T_8bd2c_row2_col3, #T_8bd2c_row3_col2, #T_8bd2c_row3_col3, #T_8bd2c_row4_col2, #T_8bd2c_row4_col3, #T_8bd2c_row5_col2, #T_8bd2c_row5_col3, #T_8bd2c_row6_col2, #T_8bd2c_row6_col3, #T_8bd2c_row7_col2, #T_8bd2c_row7_col3, #T_8bd2c_row8_col2, #T_8bd2c_row8_col3, #T_8bd2c_row9_col2, #T_8bd2c_row9_col3, #T_8bd2c_row10_col2, #T_8bd2c_row10_col3, #T_8bd2c_row11_col2, #T_8bd2c_row11_col3, #T_8bd2c_row12_col2, #T_8bd2c_row12_col3 {\n",
       "  background-color: #8dd3c7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8bd2c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8bd2c_level0_col0\" class=\"col_heading level0 col0\" >features</th>\n",
       "      <th id=\"T_8bd2c_level0_col1\" class=\"col_heading level0 col1\" >dtypes</th>\n",
       "      <th id=\"T_8bd2c_level0_col2\" class=\"col_heading level0 col2\" >NaN count</th>\n",
       "      <th id=\"T_8bd2c_level0_col3\" class=\"col_heading level0 col3\" >NaN percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8bd2c_row0_col0\" class=\"data row0 col0\" >TEXT</td>\n",
       "      <td id=\"T_8bd2c_row0_col1\" class=\"data row0 col1\" >object</td>\n",
       "      <td id=\"T_8bd2c_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8bd2c_row1_col0\" class=\"data row1 col0\" >SENTIMENT</td>\n",
       "      <td id=\"T_8bd2c_row1_col1\" class=\"data row1 col1\" >object</td>\n",
       "      <td id=\"T_8bd2c_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8bd2c_row2_col0\" class=\"data row2 col0\" >TIMESTAMP</td>\n",
       "      <td id=\"T_8bd2c_row2_col1\" class=\"data row2 col1\" >object</td>\n",
       "      <td id=\"T_8bd2c_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8bd2c_row3_col0\" class=\"data row3 col0\" >USER</td>\n",
       "      <td id=\"T_8bd2c_row3_col1\" class=\"data row3 col1\" >object</td>\n",
       "      <td id=\"T_8bd2c_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8bd2c_row4_col0\" class=\"data row4 col0\" >PLATFORM</td>\n",
       "      <td id=\"T_8bd2c_row4_col1\" class=\"data row4 col1\" >object</td>\n",
       "      <td id=\"T_8bd2c_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8bd2c_row5_col0\" class=\"data row5 col0\" >HASHTAGS</td>\n",
       "      <td id=\"T_8bd2c_row5_col1\" class=\"data row5 col1\" >object</td>\n",
       "      <td id=\"T_8bd2c_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_8bd2c_row6_col0\" class=\"data row6 col0\" >RETWEETS</td>\n",
       "      <td id=\"T_8bd2c_row6_col1\" class=\"data row6 col1\" >int8</td>\n",
       "      <td id=\"T_8bd2c_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_8bd2c_row7_col0\" class=\"data row7 col0\" >LIKES</td>\n",
       "      <td id=\"T_8bd2c_row7_col1\" class=\"data row7 col1\" >int8</td>\n",
       "      <td id=\"T_8bd2c_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_8bd2c_row8_col0\" class=\"data row8 col0\" >COUNTRY</td>\n",
       "      <td id=\"T_8bd2c_row8_col1\" class=\"data row8 col1\" >object</td>\n",
       "      <td id=\"T_8bd2c_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_8bd2c_row9_col0\" class=\"data row9 col0\" >YEAR</td>\n",
       "      <td id=\"T_8bd2c_row9_col1\" class=\"data row9 col1\" >int16</td>\n",
       "      <td id=\"T_8bd2c_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row9_col3\" class=\"data row9 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_8bd2c_row10_col0\" class=\"data row10 col0\" >MONTH</td>\n",
       "      <td id=\"T_8bd2c_row10_col1\" class=\"data row10 col1\" >int8</td>\n",
       "      <td id=\"T_8bd2c_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row10_col3\" class=\"data row10 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_8bd2c_row11_col0\" class=\"data row11 col0\" >DAY</td>\n",
       "      <td id=\"T_8bd2c_row11_col1\" class=\"data row11 col1\" >int8</td>\n",
       "      <td id=\"T_8bd2c_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row11_col3\" class=\"data row11 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8bd2c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_8bd2c_row12_col0\" class=\"data row12 col0\" >HOUR</td>\n",
       "      <td id=\"T_8bd2c_row12_col1\" class=\"data row12 col1\" >int8</td>\n",
       "      <td id=\"T_8bd2c_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "      <td id=\"T_8bd2c_row12_col3\" class=\"data row12 col3\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7986d1d730>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def null_count():\n",
    "    return pd.DataFrame({'features': df.columns,\n",
    "                'dtypes': df.dtypes.values,\n",
    "                'NaN count': df.isnull().sum().values,\n",
    "                'NaN percentage': df.isnull().sum().values/df.shape[0]}).style.background_gradient(cmap='Set3',low=0.1,high=0.01)\n",
    "null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "745885d9-8b16-4501-ba62-1b776e051856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df130a91-110b-49de-a219-3f264b03aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65400c0c-76bc-41c9-ad27-bb1aeced5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    num_distinct_values = len(df[column].unique())\n",
    "    print(f\"{column}: {num_distinct_values} distinct values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae70d0-ea2d-4d78-98ec-658703e447af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PLATFORM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df227136-e788-4834-984a-1a98e39df968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PLATFORM'] = df['PLATFORM'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f1598-b3db-475a-86ed-eaaeb7cac294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.lower().capitalize() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f96a6-3894-44c5-b103-b75398779174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0677210-104f-4f4a-9988-f0339116c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = df['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0eac6-884d-4248-a9c7-49f671f01bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "df['Day_of_Week'] = df['Timestamp'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2792f7-4762-408c-a274-ba6891bea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mapping = {\n",
    "    1: 'January',\n",
    "    2: 'February',\n",
    "    3: 'March',\n",
    "    4: 'April',\n",
    "    5: 'May',\n",
    "    6: 'June',\n",
    "    7: 'July',\n",
    "    8: 'August',\n",
    "    9: 'September',\n",
    "    10: 'October',\n",
    "    11: 'November',\n",
    "    12: 'December'\n",
    "}\n",
    "\n",
    "df['Month'] = df['Month'].map(month_mapping)\n",
    "\n",
    "df['Month'] = df['Month'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e2da0-2040-477f-805d-7410cb218912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')  # If you're using sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea295ab-7948-4930-9053-b05f91235199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize stemmer and stop words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set()  # Define your stop words here\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  \n",
    "    text = \" \".join(text.split())\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    cleaned_tokens = [stemmer.stem(token) for token in tokens\n",
    "    if token.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "# Apply the clean function to the 'Text' column\n",
    "    df[\"Clean_Text\"] = df[\"Text\"].apply(clean)\n",
    "    df[\"Clean_Text\"] = df[\"Text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d67a6-1cea-4ef9-853b-8791ca4323a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b39015-d096-4f34-b6b3-3f4ddca4870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19444e-1d0a-468d-8576-d060b750ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "specified_columns = ['Platform','Country', 'Year','Month','Day_of_Week']\n",
    "\n",
    "for col in specified_columns:\n",
    "    total_unique_values = df[col].nunique()\n",
    "    print(f'Total unique values for {col}: {total_unique_values}')\n",
    "\n",
    "    top_values = df[col].value_counts()\n",
    "\n",
    "    colors = [Fore.RED, Fore.GREEN, Fore.YELLOW, Fore.BLUE, Fore.MAGENTA, Fore.CYAN, Fore.WHITE, Fore.LIGHTBLACK_EX, Fore.LIGHTRED_EX, Fore.LIGHTGREEN_EX]\n",
    "\n",
    "    for i, (value, count) in enumerate(top_values.items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        print(f'{color}{value}: {count}{Fore.RESET}')\n",
    "\n",
    "    print('\\n' + '=' * 30 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602784e-5c30-4235-88fa-bb3cf199e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8c422-2db9-4b39-92eb-6d42ee4ead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720b30a-65e2-4592-a7f3-8894b9d4f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#66b3ff', '#99ff99', '#ffcc99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5676d6-44e8-48bc-af42-0172c56432af",
   "metadata": {},
   "outputs": [],
   "source": [
    "explode = (0.1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0340ef6-c0ab-40a2-b4cc-70ea9c276880",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = df1.groupby(\"Sentiment\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af23d62-7cd2-4381-a9b6-9e2e418280c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize stemmer and stop words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set()  # Define your stop words here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912a549-daff-4e78-b30e-fc846f606300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize stemmer and stop words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set()  # Define your stop words here\n",
    "\n",
    "def clean(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"  # Handle NaN values\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)  \n",
    "    text = \" \".join(text.split())\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    cleaned_tokens = [stemmer.stem(token) for token in tokens if token.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "# Assuming df1 is your DataFrame with a 'Text' column\n",
    "    df1[\"Clean_Text\"] = df1[\"Text\"].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b109a7-0127-4ac9-9cd6-2fd3a0d5307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3028b-7d09-4fe1-8d97-1de8688bdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e435b47-9c28-4037-a32f-7bb27fb3a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df1['Vader_Score'] = df1['Text'].apply(lambda text: analyzer.polarity_scores(text)['compound'])\n",
    "\n",
    "df1['Sentiment'] = df1['Vader_Score'].apply(lambda score: 'positive' if score >= 0.05 else ('negative' if score <= -0.05 else 'neutral'))\n",
    "\n",
    "print(df1[['Text', 'Vader_Score', 'Sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc1a5f3-b6b4-48c8-8429-84bd647ff4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#66b3ff', '#99ff99', '#ffcc99']\n",
    "\n",
    "explode = (0.1, 0, 0)  \n",
    "\n",
    "sentiment_counts = df1.groupby(\"Sentiment\").size()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    x=sentiment_counts, \n",
    "    labels=sentiment_counts.index,\n",
    "    autopct=lambda p: f'{p:.2f}%\\n({int(p*sum(sentiment_counts)/100)})', \n",
    "    wedgeprops=dict(width=0.7),\n",
    "    textprops=dict(size=10, color=\"r\"),  \n",
    "    pctdistance=0.7,\n",
    "    colors=colors,\n",
    "    explode=explode,\n",
    "    shadow=True)\n",
    "\n",
    "center_circle = plt.Circle((0, 0), 0.6, color='white', fc='white', linewidth=1.25)\n",
    "fig.gca().add_artist(center_circle)\n",
    "\n",
    "ax.text(0, 0, 'Sentiment\\nDistribution', ha='center', va='center', fontsize=14, fontweight='bold', color='#333333')\n",
    "\n",
    "ax.legend(sentiment_counts.index, title=\"Sentiment\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "ax.axis('equal')  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1270f-7835-4ab8-a05e-0f51eec128c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Year', hue='Sentiment', data=df1, palette='Paired')\n",
    "plt.title('Relationship between Years and Sentiment')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4dc5e8-c169-44de-ad67-3a91152cedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Month', hue='Sentiment', data=df1, palette='Paired')\n",
    "plt.title('Relationship between Month and Sentiment')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c270d-fb74-40d7-9267-7a36b75e8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Day_of_Week', hue='Sentiment', data=df1, palette='Paired')\n",
    "plt.title('Relationship between Day of Week and Sentiment')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd229f90-dd31-46cf-8e02-c5043a7397ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Platform', hue='Sentiment', data=df1, palette='Paired')\n",
    "plt.title('Relationship between Platform and Sentiment')\n",
    "plt.xlabel('Platform')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a8502-729a-4862-843b-eebf01d593b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "top_10_countries = df1['Country'].value_counts().head(10).index\n",
    "\n",
    "df_top_10_countries = df1[df1['Country'].isin(top_10_countries)]\n",
    "\n",
    "sns.countplot(x='Country', hue='Sentiment', data=df_top_10_countries, palette='Paired')\n",
    "plt.title('Relationship between Country and Sentiment (Top 10 Countries)')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1081b-37da-4668-915c-93a519a51359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['temp_list'] = df1['Text'].apply(lambda x: str(x).split())\n",
    "top_words = Counter([item for sublist in df1['temp_list'] for item in sublist])\n",
    "top_words_df = pd.DataFrame(top_words.most_common(20), columns=['Common_words', 'count'])\n",
    "\n",
    "top_words_df.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f25a0a-d4da-4464-84c5-e8b7fbb0ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_sent = df1[df1['Sentiment'] == 'positive']\n",
    "Negative_sent = df1[df1['Sentiment'] == 'negative']\n",
    "Neutral_sent = df1[df1['Sentiment'] == 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da0edf-6741-45cd-a476-ccbcf0375495",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in df1[df1['Sentiment'] == 'positive']['temp_list'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20), columns=['Common_words', 'count'])\n",
    "temp_positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab272146-d95f-4b2c-9c39-f2a20fb4e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join([item for sublist in df1[df1['Sentiment'] == 'positive']['temp_list'] for item in sublist])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(words)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3f931-0d8d-4bca-a829-f9397312752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in df1[df1['Sentiment'] == 'neutral']['temp_list'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(10), columns=['Common_words', 'count'])\n",
    "temp_positive.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07a505-ccd5-40ca-9882-abeeae9f81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join([item for sublist in df1[df1['Sentiment'] == 'neutral']['temp_list'] for item in sublist])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(words)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d38873-2c61-4eb5-ac8a-b93adac95a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = Counter([item for sublist in df1[df1['Sentiment'] == 'negative']['temp_list'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20), columns=['Common_words', 'count'])\n",
    "temp_positive.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9f78c-eec9-4dc2-a258-bf70af4e2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join([item for sublist in df1[df1['Sentiment'] == 'negative']['temp_list'] for item in sublist])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(words)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d251c12-2191-4d9b-be6f-4fbdcdaf7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1285f-1133-4c47-a394-94915b02c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda2d6f-1d89-4ad1-8c21-31c3ef59426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['Text'].values\n",
    "y = df2['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94741c7-8a62-48ac-9eb1-479e18ac7ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71973b7-5889-4fdf-8343-8e1e2e8c8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748c22d-a615-44b0-a080-db94ed159140",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_classifier = PassiveAggressiveClassifier(max_iter=50, random_state=42)\n",
    "pac_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107fd84-8d37-4fb0-8e25-3775698e3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pac_classifier.predict(X_test_tfidf)\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "classification_rep_test = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4a099-3e13-4ea7-b2de-6d805c5a23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Set Results:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(\"Classification Report:\\n\", classification_rep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8487e-5a21-4de4-adf4-69044bead8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'C': [0.1, 0.5, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'shuffle': [True, False],\n",
    "    'verbose': [0, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b849e14-d6df-430a-9709-aec483dd0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_classifier = PassiveAggressiveClassifier(random_state=42)\n",
    "\n",
    "randomized_search = RandomizedSearchCV(pac_classifier, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "randomized_search.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf43ea-4880-43d2-8cf8-b39c1d3a3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_randomized = randomized_search.best_params_\n",
    "best_params_randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c173aed-549d-4847-95b8-a4904e0ef0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pac_classifier_randomized = PassiveAggressiveClassifier(random_state=42, **best_params_randomized)\n",
    "best_pac_classifier_randomized.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecb727-0dda-48f1-84c9-8a7eb31b9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best_pac_randomized = best_pac_classifier_randomized.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e1084-dd8a-4c3d-bda3-fcc6657a447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_best_pac_randomized = accuracy_score(y_test, y_pred_best_pac_randomized)\n",
    "classification_rep_best_pac_randomized = classification_report(y_test, y_pred_best_pac_randomized)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_best_pac_randomized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912650f-3fb2-4b56-a70c-065d66538aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best PassiveAggressiveClassifier Model (RandomizedSearchCV):\")\n",
    "print(f\"Best Hyperparameters: {best_params_randomized}\")\n",
    "print(f\"Accuracy: {accuracy_best_pac_randomized}\")\n",
    "print(\"Classification Report:\\n\", classification_rep_best_pac_randomized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ccb604-7372-4b6d-8324-aeb99fc00388",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Greys', xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])\n",
    "plt.title('Confusion Matrix - Hyperparameters')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e07b3f-9666-4f8f-a4d6-650ebd0f5935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b574a-1c08-4827-b993-3e1a311a402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('output2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3a333-1c76-4f3b-9e07-0dcc244af0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install snowflake-connector-python[pandas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f9cc3-4412-4b52-9558-7ae1636c7001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
